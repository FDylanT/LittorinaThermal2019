---
title: "LittorinaStatistics"
author: "Ffion Titmuss"
date: "3/24/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

setwd("~/Repos/LittorinaThermal2019")

## Load packages
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lme4)
library(blme)
```

## Load data
```{r}
litt <- read.csv("./data/LittorinaData.csv", header = TRUE) %>%
 rename(Spp = Genus_Species)

#mort_B23_hrs <- litt %>%
#  filter(PreTrtMortNotes != "dead") %>% # remove larvae that died during acclimation or were misidentified
#  filter(Block == 2 | Block == 3) %>%
#  rename("24" = TrtDay1_Survived, "48" = TrtDay2_Survived) %>% # convert trt days to hours
#  mutate("0" = TRUE) %>% # add time point 0 where all samples were alive
#  gather("0", "24", "48", key = "Time_hrs", value = "Survived") %>%
#  mutate(Alive = as.integer(Survived)) %>%
#  mutate(Dead = ifelse(Alive == 1, 0, 1))

mort_B23 <- litt %>%
  filter(PreTrtMortNotes != "dead") %>% # remove larvae that died during acclimation or were misidentified
  filter(Block == 2 | Block == 3) %>%
  mutate(DaysAlive = ifelse(TrtDay2_Survived == TRUE, 2, ifelse(TrtDay1_Survived == TRUE, 1, 0))) %>%
  mutate(DaysDead = 2 - DaysAlive) %>%
  mutate(PropDaysAlive = DaysAlive/2)
```

## Tests on mortality
Met with Katie & Molly on 11/17/20 -- models as written below failed to converge, so trying again with recoded data
```{r}
mort1 <- glmer(cbind(Alive, Dead) ~ Spp + PopID + Trt + Time_hrs +
              (1|Block) + (1|SampleID) + (1|Seatable), 
              family = binomial(), control = glmerControl(optimizer = "bobyqa"),
              data = mort_B23)
summary(mort1) # So it works with block ONLY. 

# Extract and Plot.
newdata = expand.grid(Spp = unique(mort_B23$Spp),
                      Block = unique(mort_B23$Block),
                      PopID = unique(mort_B23$PopID),
                      Trt = unique(mort_B23$Trt),
                      Time_hrs = unique(mort_B23$Time_hrs))
survival = predict(mort1,newdata)
newdata$survival = plogis(survival)

newdata$group = paste(newdata$PopID,newdata$Trt,sep = "_")

# Holy error bars
ggplot(newdata, aes(x = Time_hrs, y = survival, group = group,shape = Trt, colour = PopID)) + 
  geom_point() +
  stat_smooth(se=TRUE) + 
  facet_wrap(~Spp) + 
  theme_classic()

#mort1 <- glmer(cbind(Alive, Dead) ~ Spp + PopID + Trt + Time_hrs + (1|Block) + (1|Seatable) + (1|SampleID),
#               family = binomial(),
#               data = mort_B23,
#               control = glmerControl(optimizer = "bobyqa"))

#mort1 <- glmer(cbind(Alive, Dead) ~ Spp + PopID + Trt + Time_hrs + (1|Block) + (1|Seatable),
#               family = binomial(),
#               data = mort_B23,
#               control = glmerControl(optimizer = "bobyqa"))

#mort1 <- glmer(cbind(Alive, Dead) ~ Spp + PopID + Trt + Time_hrs + (1|Block),
#               family = binomial(),
#               data = mort_B23,
#               control = glmerControl(optimizer = "bobyqa"))

#mort1 <- glmer(cbind(Alive, Dead) ~ Spp + PopID + Trt + Time_hrs + (1|Block) + (1|Seatable) + (1|SampleID:Seatable),
#               family = binomial(),
#               data = mort_B23,
#               control = glmerControl(optimizer = "bobyqa"))

#mort1 <- bglmer(cbind(Alive, Dead) ~ Spp + PopID + Trt + Time_hrs + (1|Block) + (1|Seatable) + (1|SampleID),
#               family = binomial(),
#               data = mort_B23)

mort2 <- glmer(cbind(Alive, Dead) ~ Spp + PopID + Trt + Time_hrs + (1|Block) + (1|Seatable) + (1|SampleID),
               family = binomial(),
               data = mort_B23,
               control = glmerControl(optimizer = "bobyqa",
                                      optCtrl = list(maxfun = 10000),
                                      tol = 0.001))


# This should test optimizers to see which one should work - but its not working either! 
require(dfoptim)
aa_maximal <- allFit(mort2)

```

## Trying model again after recoding data
```{r}
mort_prop <- glmer(cbind(DaysAlive, DaysDead) ~ Spp + PopID + Trt + (1|Block) + (1|Seatable),
               family = binomial(),
               data = mort_B23,
               control = glmerControl(optimizer = "bobyqa"))

summary(mort_prop)
```

```{r}
# Just for funsies - look at data in proportion format

littmort <- mort_B23 %>%
  group_by(PopID,Spp,Trt,Time_hrs,Block)%>%
  summarize(surv = sum(Alive,na.rm=TRUE),
            totalsnail = n())
littmort$propsurv = littmort$surv/littmort$totalsnail
littmort$group = paste(littmort$Spp,littmort$PopID,littmort$Trt,sep = "_")

# Okay so this is similar to the plot above. Thats good at least. 
ggplot(littmort, aes(x = Time_hrs, y = propsurv, group = group,shape = Trt, colour = PopID)) + geom_point() +stat_smooth(se=FALSE) + facet_wrap(~Spp) + theme_classic()

```
Lets try a Bayesian approach
```{r}
require(R2jags)
require(rjags)
require(lattice)

# Bernoulli
df2 <- mort_B23 %>% transform(id=as.numeric(factor(SampleID))) %>%
  transform(block = as.numeric(factor(Block))) %>%
  transform(seat = as.numeric(factor(Seatable))) %>%
  transform(time = as.numeric(factor(Time_hrs)))#transforms into numeric

##Create dataframe for model
litjag <-  c(list(y=df2$Alive,
                x = as.numeric(df2$time),
                s = as.numeric(df2$Spp),
                l = as.numeric(df2$Trt),
                po = as.numeric(df2$PopID),
                bin = df2$block,
                N=nrow(df2)))

## Bernoulli Model
model.bern<-function(){
  
  # Likelihood
  for (i in 1:N) {
    logit(p[i]) <- (ba+b0vec[bin[i]]) + beta[1]*s[i] + beta[2]*l[i] + beta[3]*po[i] + beta[4]*x[i] # Multiple Regression
    y[i] ~ dbern(p[i])
  }
  
  ## Specify priors
  tau <- 1/(sigma*sigma) # Precision for slope
  sigma ~ dunif(0,1)
  
  for(j in 1:4){ # for slope estimate
    beta[j] ~ dnorm(0,tau) 
  }
  
  ba ~ dnorm(0,tau)
  sigma.a ~ dunif(0, 100) # standard deviation of random effect (variance between individuals)
	tau.a <- 1 / (sigma.a * sigma.a) # convert to precision
	
  for (i in 1:2){ #for intercept estimate
    b0vec[i] ~ dnorm(0,tau.a)
  }
}  
```


```{r}
##Starting values
xstart <-(list(ba = c(rep(.1,nrow(df2))),beta=c(rep(.1,nrow(df2))),b0vec=c(rep(.1,nrow(df2)))))
##Create a list of starting values that will be used for each chain based on xstart above
xstart2 = list(
  as.list(unlist(xstart)*runif(length(xstart),0.009,.011)),
  as.list(unlist(xstart)*runif(length(xstart),0.09,.11)),
  as.list(unlist(xstart)*runif(length(xstart),0.9,1.1)))

## Runs the dang thang
b1=jags(model.file=model.bern, # lots of warnings because my start values are way off. Ignore them for now...  
           data=litjag,
           parameters.to.save=c("ba","beta","b0vec"),
           inits = xstart2,
           #nits=c(list(xstart),xstart2), 
           n.chains=3, # 3 mcmc chains
           n.iter=5000) # 2500 burn in (burn in = unused)
```


```{r}
##Get Outputs
mod_1 <- b1$BUGSoutput
print(mod_1,digits=4)

## View diagnostic plots etc. to check convergence
plot(mod_1) ##View plot of parameter estimates and errors
b2 <- as.mcmc.list(mod_1) 
devpos <- which(colnames(b2[[1]])=="deviance")
b3 <- b2[,-devpos] ## drop deviance estimates
class(b3) <- "mcmc.list"
dev.off()
xyplot(b3,asp="fill") ##Visual inspection of Markov chain behavior
densityplot(b3,asp="fill") ##Density plot for parameter estimates
gelman.diag(b2) #provides the Gelman-Rubin statistics # Rule of thumb - anything less than 1.2 is okay
```


```{r}
##Generate Predicted Survival through time from Posterior Distribution


# Fixed effects are all numeric form but can be converted back - 
# For words like species name, R goes in alphabetical order so 1 = first alphabetical name, 2 = second in alphabetical order
# Numbers go in numerical order (duh)- so time =1 is time 0, time=2 is 24 hrs... etc.

#Fixed Effects
Time_hrs<-df2$time #beta[4]
Spp = as.numeric(df2$Spp) #beta[1]
Trt = as.numeric(df2$Trt) # beta[2]
PopID = as.numeric(df2$PopID) #beta[3]
Int = ((mean(b2[[1]][,1])+mean(b2[[1]][,3])) + (mean(b2[[1]][,2])+mean(b2[[1]][,3])))/2 # int =average of (ba+block1) + (ba_block2) from mod_1

# Estimation Function
predict_surv<-function(pars,Int,Time_hrs,Trt,Spp,PopID) #pars = variable that will be substituted for b2[[1]] in subsequent code
{
  #b0<-mean(as.vector(pars[,j+2])      #intercept
  b1<-as.vector(pars[,4]) # species slope
  b2<-as.vector(pars[,5]) # trt slope
  b3<-as.vector(pars[,6]) # PopID slope
  b4<-as.vector(pars[,7]) # Time slope
  pred_surv<- Int + (b1 * Spp) + (b2 * Trt) + (b3 * PopID) + (b4 * Time_hrs)
  pred_surv ~ dbern(pred_surv)
  return(plogis(pred_surv))
}

## Generate predictions
out_dat2<-data.frame()

for(j in 1:length(unique(Time_hrs))){
  for(k in 1:length(unique(Trt))){
    for(l in 1:length(unique(Spp))){
      for(m in 1:length(unique(PopID))){
        
        pred<-predict_surv(b2[[1]],Int,unique(Time_hrs)[j],unique(Trt)[k],unique(Spp)[l],unique(PopID)[m]) # Puts each value through function
        
        out=data.frame("Time" = unique(Time_hrs)[j],
              "Trt" = unique(Trt)[k],
              "Spp" = unique(Spp)[l],
              "PopID" = unique(PopID)[m],
              "mean" = mean(pred), # this is output from function - mean survival
              "median" = median(pred),
              "quantile_lwr" = quantile(pred,p=c(0.025,0.975))[1],
              "quantile_upr" = quantile(pred,p=c(0.025,0.975))[2])
        out_dat2<-rbind(out_dat2,out)
      }
      }
    }
}


out_dat2$group = paste(out_dat2$PopID,out_dat2$Trt,sep = "_")
ggplot(out_dat2, aes(x = factor(Time), y = mean, group = group ,shape = factor(Trt), colour = factor(PopID))) + 
  geom_point() + 
  geom_line()+ 
  ylab("Mean Survival") + xlab("Time")+
  geom_errorbar(aes(ymin = quantile_lwr, ymax = quantile_upr,width = 0.1))+ 
  facet_wrap(~Spp) + 
  theme_classic()

## Good - this resembles our raw data plot and the plot from the mort1 predicted values. 

## We can PROBABLY incorporate more random effects into this model now that i have it working. Talk it over with Katie to figure out the best next steps. Like I mentioned- Bayesian is MOTHER FUCKING COOL (and fun) but may not be the best for your purposes because its harder to test significance. If Katie is okay with just having a block effect as the only random effect, the glmer approach might be easiest. But if you want to add any other random effects, then we'll have to use the Bayesian approach to estimate your parameters. I will help you through it if thats the route you decide - but this is a good first step in introducing you to the bones of how bayesian models work. If you don't use this - no worries! Its been a fun reminder for myself. 


```
